\chapter{Introduction}

\textit{``... Pleasure has probably been the main goal all along. But I hesitate to admit it, because computer scientists want to maintain their image as hard-working individuals who deserve high salaries. Sooner or later society will realize that certain kinds of hard work are in fact admirable even though they are more fun than just about anything else. (Knuth 1993)''} \cite{oneliners}

Computers are being used for amazing things. There are computers that can verify faces with sight, computers that can determine music by hearing it, and computers that react to touch. But, with all of these advancements, programmers have yet to provide computers with the most important, essential, and human sense: a sense of humor. This is a sense so complicated that, while we have hearing aids and glasses, nothing fixes a terrible sense of humor. But maybe modern technology can help.

Much work has been done in the field of computational humor, both in trying to understand and generate humor. Although there has been success in humor identification, it has always been directed at understanding specific kinds of jokes. For example, understanding if a sentence can be made into a ``That's What She Said'' joke\cite{twss} is great, but their technique only works for that specific kind of joke. One liner identification \cite{oneliners} and pun generators, although great achievements in the field of computational humor, still suffer from being about a specific form of joke, and thus are hard to apply outside of their scope.

Laff-O-Tron attempts to widen the scope of humor recognition beyond narrow joke structures by attempting to predict laughter in TED talks.

\section{Laugh Prediction}
Laugh prediction is the ability to, after a line is said, predict how likely it is that it will be followed by a laugh. In a sense, this is trying to identify whether something was a punchline of a funny joke, without needing to discover what the joke is or why it is funny. We believe this can be done by analyzing paragraph structure and word choice, as well as humorous stylistics.

\section{Applications of Laugh Prediction}
Laughter is an essential part of being human, and humor has been ingrained into our species no matter the culture. On a grand scale, an AI that is able to laugh at a correct time would be a major step towards creating a more human like AI. However, let's look at more immediate uses for laugh prediction as well.

When it comes to researching humor, laugh prediction will allow new perspectives on joke structure and design. This can provide new insight on the joke telling process. With some fine tuning, a user might be able to practice their delivery style on specific environments; such as wedding ceremonies or political speeches. 

Laugh prediction could be used to test if something will merit a laugh in fields like advertising. This is important, as the repercussions from poorly made jokes can be massive when it comes to major advertisements. However, this risk comes with high reward, as humorous commercials tend to be memorable.

Lastly, laugh prediction will be able to improve human computer interaction when it comes to vocal communication. It will make the computer appear more human, as it will appear to have a sense of humor. Adding humor into human computer interaction has been proven to improve people's opinions of it.\cite{Teaching}\cite{Multi-Humoroid} Imagine a world where you can tell Siri or Cortana a joke, and it would be able to laugh (or groan) accordingly. 

\section{Laff-O-Tron}
This work outlines an application, referred to as Laff-O-Tron, which attempts to predict when there will be laughter in a text script. Laff-O-Tron uses machine learning and natural language processing (NLP) to analyze the script, and make predictions after each line based off of the training scripts. Laff-O-Tron was trained using transcripts from TED Talks and was successfully able to predict laughter. We believe that with a different training corpus, Laff-O-Tron can be used to predict laughter or even applause in other environments such as political speeches.

\section{Why TED Talks?}
In order to train Laff-O-Tron, we needed data where the laughter had already been identified. Rather than manually adding laughter to scripts we already had, we decided to find new scripts that already had laughter marked down. After a thorough investigation, we found that TED Talk transcripts had audience laughter already marked, and decided to use them as our data. This design choice greatly impacts how Laff-O-Tron works, as environment has an incredible impact on humor. The kind of humor that is prevalent in bars, for example, is different than the humor found at a wedding. Thus, Laff-O-Tron is designed to predict laughter in a live talk environment. 


\section{Contribution}
The goal of this project was to show that it is possible for a computer system to be able to predict laughter without needing depending on a narrow joke structure such as knock knock joke or pun. Although Laff-O-Tron was a success, more research needs to be done to generalize this beyond TED Talks. 

This project has also contributed to the field of NLP as a whole by creating a corpus of TED Talks, free to use by anyone.
